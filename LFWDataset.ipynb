{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDqfRldZSDds"
      },
      "source": [
        "# IA Project - Face Recognition with Dynamic Triplet Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74ceGeGASHIC"
      },
      "source": [
        "References: https://openaccess.thecvf.com/content_ICCV_2019/papers/Zhang_Learning_Local_Descriptors_With_a_CDF-Based_Dynamic_Soft_Margin_ICCV_2019_paper.pdf\n",
        "\n",
        "Dataset: http://vis-www.cs.umass.edu/lfw/#download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhRpOYJZR_ne"
      },
      "source": [
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms.functional as TF\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "import collections\n",
        "import PIL.Image\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import os\n",
        "import random"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKIejUZSSJq8",
        "outputId": "1e60d293-e700-458d-f11c-6334df56749a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(dev)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkFSjhnQSLt7"
      },
      "source": [
        "### Pre-precessing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdSQ4aNRSNyr"
      },
      "source": [
        "#path\n",
        "data_path = \"./LFW_DIR\"\n",
        "train_path = \"./data/train_pairs.txt\"\n",
        "test_path = \"./data/test_pairs.txt\"\n",
        "people_path = \"./data/people.txt\""
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywc2QkEkvM2c"
      },
      "source": [
        "norm_mean = (0.485, 0.456, 0.406)\n",
        "norm_std = (0.229, 0.224, 0.225)\n",
        "\n",
        "test_transform = T.Compose([\n",
        "    T.Resize(250),  # make 250x250\n",
        "    T.CenterCrop(150),   # then take 150x150 center crop\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(norm_mean, norm_std),\n",
        "])\n",
        "\n",
        "train_transform = T.Compose([\n",
        "    T.Resize(250),\n",
        "    T.RandomCrop(150),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(norm_mean, norm_std),\n",
        "])"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73VKzt_sSO87"
      },
      "source": [
        "def readPeople(people_path):\n",
        "  people_list = []\n",
        "  with open(people_path, 'r') as file:\n",
        "    for line in file.readlines():\n",
        "      person = line.strip().split()\n",
        "      people_list.append(person)\n",
        "  return people_list"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPQxtfRlTTgd"
      },
      "source": [
        "people_list= readPeople(people_path)\n",
        "people_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzDt37ceTdsp",
        "outputId": "7dd65724-8ecf-43a4-eca0-bb8dcf227f17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''\n",
        "# loading dataset\n",
        "# dataset = datasets.ImageFolder(data_path, transform = transform)\n",
        "dataset = datasets.ImageFolder(data_path)\n",
        "print(f\"num samples: {len(dataset)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num samples: 13233\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ci_gKYOUAgv"
      },
      "source": [
        "'''\n",
        "# devo estrarre un subset delle persone con un numero di immagini >1\n",
        "# mi serve una lista della label delle persone \n",
        "#ciclo people_list: se il numero di immagini per persona è >1 copio quella persona\n",
        "# in una lista di classi. poi queste classi le converto in label e faccio il subset\n",
        "\n",
        "def getIndeces(dataset, people_list):\n",
        "\n",
        "  people_idx = []\n",
        "  data_dict = dataset.class_to_idx\n",
        "\n",
        "  for person in people_list:\n",
        "    if int(person[1]) > 1:\n",
        "      name = person[0]\n",
        "      people_idx.append(data_dict[name])\n",
        "\n",
        "  return people_idx\n",
        "  '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEsJkoEZjUxc"
      },
      "source": [
        "'''\n",
        "people_idx = getIndeces(dataset, people_list)\n",
        "people_idx      #lista delle labels relative alle persone con più di un'immagine\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bmPIKu4RaXN"
      },
      "source": [
        "'''\n",
        "# cambiare i nomi con le labels\n",
        "def getLabeledImages(data_path, people_list):\n",
        "  img_path = []\n",
        "  people_idx = []\n",
        "  labeledImages = {}\n",
        "  i = 0\n",
        "  # data_dict = dataset.class_to_idx\n",
        "\n",
        "  for person in people_list:\n",
        "    if int(person[1]) > 1:    # se ho più di una immagine per persona\n",
        "      label = i\n",
        "      # people_idx.append(data_dict[name])\n",
        "      labeledImages[label] = []\n",
        "      for j in range(int(person[1])):\n",
        "        path = os.path.join(data_path, person[0], person[0] + '_' + '%04d' % int(person[1]) + '.jpg')\n",
        "        img_path.append(path)\n",
        "      labeledImages[i] = img_path\n",
        "      img_path = []\n",
        "      i += 1\n",
        "\n",
        "  return labeledImages"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgSGZx3JadkX"
      },
      "source": [
        "# cambiare i nomi con le labels\n",
        "def getLabeledImages(data_path, people_list):\n",
        "  labeledImages = {}\n",
        "  label = 0\n",
        "  \n",
        "\n",
        "  for person in people_list:\n",
        "    if int(person[1]) > 1:    # se ho più di una immagine per persona\n",
        "      for img_id in range(1, int(person[1])+1):\n",
        "        path = os.path.join(data_path, person[0], person[0] + '_' + '%04d' % img_id + '.jpg')\n",
        "        labeledImages[path] = label\n",
        "      label += 1\n",
        "\n",
        "  return labeledImages"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxHovEu-U9rt",
        "outputId": "f26f74ce-df5a-40f0-cc00-c96b6f424c26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "labeledImages = getLabeledImages(data_path, people_list)\n",
        "print(len(labeledImages.keys()))    # dizionario 'img_path: label'\n",
        "print(len(set(labeledImages.values())))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9164\n",
            "1680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m02XOztVc_T"
      },
      "source": [
        "class LFWDataset(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, labeledImages, transform, train = True):\n",
        "    self.train = train\n",
        "    self.transform = transform\n",
        "    self.labeledImages = labeledImages\n",
        "    self.images = list(labeledImages.keys())\n",
        "    # self.index = list(range(len(labeledImages.key()))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    anchor_path = self.images[index]\n",
        "\n",
        "    if self.train:\n",
        "      anchor_label = self.labeledImages[anchor_path]\n",
        "\n",
        "      # get positive image path\n",
        "      positive_list = [item for item in self.images if self.labeledImages[item] == anchor_label and item != anchor_path]\n",
        "      positive_path = random.choice(positive_list)\n",
        "\n",
        "      # get negative image path\n",
        "      negative_list = [item for item in self.labeledImages.keys() if item not in positive_list]\n",
        "      negative_path = random.choice(negative_list)\n",
        "\n",
        "      # get images from paths\n",
        "      anchor_img = PIL.Image.open(anchor_path)\n",
        "      positive_img = PIL.Image.open(positive_path)\n",
        "      negative_img = PIL.Image.open(negative_path)\n",
        "\n",
        "      # transform images\n",
        "      anchor_img = self.transform(anchor_img)\n",
        "      positive_img = self.transform(positive_img)\n",
        "      negative_img = self.transform(negative_img)\n",
        "\n",
        "      return anchor_img, positive_img, negative_img"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRDiltBqf_Zj",
        "outputId": "007c45a7-115c-49d6-db58-aa350ee444fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "train_dataset = LFWDataset(labeledImages, train_transform)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-117-7a80a7f83ebf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLFWDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeledImages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: torch.Size() takes an iterable of 'int' (item 0 is 'Tensor')"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBhzGMdrl37U"
      },
      "source": [
        "'''\n",
        "num_data = len(dataset)\n",
        "list_idx = list(range(num_data))\n",
        "random.shuffle(list_idx)\n",
        "\n",
        "train_frac = 0.5\n",
        "test_frac = 0.3\n",
        "val_frac = 0.2\n",
        "\n",
        "# training\n",
        "num_train = int(num_data*train_frac)\n",
        "num_data = num_data - num_train\n",
        "train_idx = list_idx[num_data:]\n",
        "list_idx = list_idx[:num_data]\n",
        "\n",
        "# test\n",
        "num_test = int(num_data*test_frac)\n",
        "num_data = num_data - num_test\n",
        "test_idx = list_idx[num_data:]\n",
        "list_idx = list_idx[:num_data]\n",
        "\n",
        "# val\n",
        "num_val= int(num_data*val_frac)\n",
        "num_data = num_data - num_val\n",
        "val_idx = list_idx[num_data:]\n",
        "list_idx = list_idx[:num_data]\n",
        "\n",
        "# create subsets\n",
        "train_dataset = Subset(dataset, train_idx)\n",
        "test_dataset = Subset(dataset, test_idx)\n",
        "val_dataset = Subset(dataset, val_idx)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkzwGbx4vPLk",
        "outputId": "9e7cde31-7ea6-4315-970a-ffa95595b6e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''\n",
        "print(\n",
        "    len(train_dataset),\n",
        "    len(test_dataset),\n",
        "    len(val_dataset)\n",
        ")\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6616 1985 926\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hKL7O-wwwbK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}